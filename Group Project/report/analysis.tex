% !TeX root = report.tex
% !TeX spellcheck = en_GB

\section{Analysis}
From the results above it seems that the structure of our input does not allow for good results.

\newpar Recurrent and acyclic neural networks as well as Turing enabled and disabled networks never (in 10.000 generations) achieve higher fitness than approximately 0.35. To put the value into perspective the result is compared to three suboptimal strategies\todo{ref excel eller appendix it}. A strategy where moves are picked randomly including non-edges will result in an average fitness of 0.000126. A strategy which randomly picks legal moves will get an average fitness of 0.67 and a strategy which always moves away from the goal will get a fitness of 0.25. The span between these numbers are great, and it is clear that as soon as a strategy learns to not pick non-edges the fitness greatly increases. The observation is therefore that the champion must have some understanding of the graph but only enough so that it most of the time does not pick non-edges. The strategy of always moving away from the goal is in some sense just as hard a problem as the shortest path to the goal, therefore it is not likely that the champion uses this strategy. 

To further analyse the champions we examine the behaviour of the champion on a collection of graphs. On a small sample size of graphs we tried to see the outputs 

\begin{figure}
	0:	0.5 \\
	1:	0.5	\\
	2:	0.5	\\
	3:	0.99999 \\
	4:	0.5	\\
	5:	0.5	\\
	6:	0.99392 \\
	7:	0.99994 \\
	8:	0.5	\\
	9:	0.5 \\
	\caption The network is on vertex 1 and should move to 7 but picks 3.
\end{figure}

\newpar One possible reason for this, might be that the encoding of the problem is not feasible for the ENTM. If we compare our encoding to that of the Copy Task from \cite{greve2016evolving}, they made sure to signal the network when starting a new assignment and when asking it to return the content back. Also, they supplied the input in multiple time-steps rather than giving the entire sequence all at once.

\newpar The shortest path problem differ from the Copy task in that the memory bank should not only be used to store content as provided. It should be used to model some structure that would allow for the planning problem to be performed. Since we ask for output in every iteration (also the first), we don't allow the ENTM to preprocess anything. This might be another place to tweak the problem encoding. Further experiments might try to feed the graph in multiple steps and different encodings, and train the network to signal when it is ready to answer on the shortest path problem.